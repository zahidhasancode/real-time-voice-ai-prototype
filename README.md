# Real-Time Voice AI Prototype (Node.js)

A real-time AI voice calling prototype built to explore **low-latency (<300ms perceived)** voice interactions using a **streaming, predictive architecture**.

This project focuses on **telephony + WebSocket audio streaming**, forming the foundation of an enterprise-grade AI voice agent platform.

---

## ðŸš€ Project Goal

The goal of this project is to prove that **human-like AI voice responses** are possible by:

- Streaming audio in real time (no batch processing)
- Avoiding REST APIs in the live call path
- Triggering AI responses **before the user finishes speaking**
- Supporting interruption and cancellation

This repository represents a **working prototype**, not a finished SaaS product.

---

## ðŸ§  Core Concepts

- One call = one dedicated async worker
- Persistent WebSocket connections
- Streaming audio (20ms frames)
- Predictive speech detection (no silence waiting)
- Cancelable AI responses
- Latency-first design

---

## ðŸ—ï¸ Current Status

âœ… Project scaffolding  
âœ… Node.js WebSocket server  
âœ… ngrok public tunnel  
âœ… Twilio Media Streams integration (in progress)  
ðŸš§ Live audio chunk verification (WIP)  
ðŸš§ Streaming STT (planned)  
ðŸš§ LLM + TTS pipeline (planned)

---

## ðŸ§© Architecture Overview

Phone Call
â†“
Twilio Media Streams (WebSocket)
â†“
Node.js WebSocket Server
â†“
[ Streaming Audio Pipeline ]
â†“
( STT â†’ LLM â†’ TTS ) â† planned


## ðŸ“ Project Structure

real-time-voice-ai-prototype/
â”œâ”€â”€ audio/ # audio buffering (planned)
â”œâ”€â”€ intent/ # intent detection logic (planned)
â”œâ”€â”€ llm/ # LLM streaming (planned)
â”œâ”€â”€ stt/ # speech-to-text (planned)
â”œâ”€â”€ tts/ # text-to-speech (planned)
â”œâ”€â”€ vad/ # voice activity detection (planned)
â”œâ”€â”€ utils/ # shared utilities
â”œâ”€â”€ ws/ # websocket handlers (planned)
â”œâ”€â”€ server.js # WebSocket server entry point
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

---

## ðŸ› ï¸ Tech Stack

- Node.js
- WebSockets
- Twilio Media Streams
- ngrok (local tunneling)

**Planned integrations:**
- Deepgram (Streaming STT)
- OpenAI (Streaming LLM)
- ElevenLabs (Low-latency TTS)

---

## âš™ï¸ Local Setup

### Prerequisites
- Node.js (v18+ recommended)
- ngrok account
- Twilio account with a phone number

---

### Installation

```bash
git clone https://github.com/zahidhasancode/real-time-voice-ai-prototype.git
cd real-time-voice-ai-prototype
npm install
Environment Variables

Create a .env file (do NOT commit it):

PORT=3000


See .env.example for reference.

Run Server
node server.js


Expose locally using ngrok:

ngrok http 3000

âš ï¸ Important Notes

This project is latency-first, not accuracy-first

REST APIs are intentionally avoided in the live audio path

This is a learning and exploration prototype

Not production-ready

ðŸ§ª Why This Project Exists

Most AI voice demos hide latency using pre-recorded audio or batch processing.

This project explores:

Real streaming constraints

Telecom-grade behavior

Predictive response strategies

Why many AI voice demos fail in real phone calls

ðŸ“Œ Roadmap

 Confirm live audio chunk streaming

 Add streaming STT (partial transcripts)

 Add predictive intent triggering

 Add streaming LLM responses

 Add chunked TTS playback

 Handle user interruptions

 Measure end-to-end latency

ðŸ“„ License

MIT (can be updated later)

ðŸ‘‹ Author

Built by Zahid Hasan
Exploring real-time AI voice systems and low-latency architectures.


